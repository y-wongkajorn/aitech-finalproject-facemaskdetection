{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_generator = ImageDataGenerator(rescale = 1/255.0,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   shear_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4568 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x = img_generator.flow_from_directory('./dataset',\n",
    "                                          target_size = (224, 224),\n",
    "                                          classes = ['with_mask','without_mask'],\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = 64,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.DirectoryIterator object at 0x000001C85DD95610>\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,430,338\n",
      "Trainable params: 172,354\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "24/72 [=========>....................] - ETA: 37s - loss: 0.1181 - accuracy: 0.8281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beany\\anaconda3\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 58s 778ms/step - loss: 0.0595 - accuracy: 0.9181\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 55s 762ms/step - loss: 0.0228 - accuracy: 0.9704\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 54s 745ms/step - loss: 0.0180 - accuracy: 0.9764\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 59s 816ms/step - loss: 0.0146 - accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 58s 802ms/step - loss: 0.0112 - accuracy: 0.9860\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 58s 802ms/step - loss: 0.0090 - accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 58s 799ms/step - loss: 0.0097 - accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 53s 739ms/step - loss: 0.0102 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 52s 715ms/step - loss: 0.0104 - accuracy: 0.9856\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 56s 781ms/step - loss: 0.0070 - accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "based_model = MobileNetV2(input_shape=(224, 224,3), include_top=False, weights=None)\n",
    "based_model.load_weights('mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n",
    "\n",
    "based_model.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(based_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(learning_rate = 0.001, decay = 0.001/20)\n",
    "model.compile(loss = 'mse', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x, batch_size=64, epochs=10)\n",
    "\n",
    "model.save('face_mask_s224.h5',save_format='h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ea3f6dbec724b47d1e51d0ac93096922af2bb2bd1c621ea9bc4ecbf15b4b2b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
